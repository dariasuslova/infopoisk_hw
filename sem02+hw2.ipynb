{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "requests??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "req = requests.get('http://hse.ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "req.text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def google(query):\n",
    "    url = 'http://google.ru/search?q={}'.format(query)\n",
    "    req = requests.get(url)\n",
    "    \n",
    "    soup = BeautifulSoup(req.text, 'lxml')\n",
    "    \n",
    "    for i, h in enumerate(soup.findAll('h3', attrs = {'class':'r'})):\n",
    "        link = h.find('a')\n",
    "        if link:\n",
    "            link['href'] = 'http://google.ru/' + link['href'] \n",
    "            link = '<i>{}.</i>  {}'.format(i, link)\n",
    "            #display(HTML(str(link)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "google('hse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обход блокировки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import socks\n",
    "import socket\n",
    "import time\n",
    "\n",
    "def create_connection(address, timeout=None, source_address=None):\n",
    "    sock = socks.socksocket()\n",
    "    sock.connect(address)\n",
    "    return sock\n",
    "\n",
    "socks.setdefaultproxy(socks.PROXY_TYPE_SOCKS5, \"127.0.0.1\", 9050)\n",
    "socket.socket = socks.socksocket\n",
    "socket.create_connection = create_connection\n",
    "        \n",
    "time.sleep(0.1)\n",
    "\n",
    "socks.socksocket().close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Семинар"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Написать краулер, который собирает ссылки со страниц румынской Википедии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://mo.wikipedia.org'\n",
    "req = requests.get(url)\n",
    "soup = BeautifulSoup(req.text, 'lxml')\n",
    "url2 = ''\n",
    "url3 = ''\n",
    "for link1 in soup.findAll('a', href = True, text=394):\n",
    "    if link1:\n",
    "        link1['href'] = 'http://mo.wikipedia.org' + link1['href'] \n",
    "        url2 = str(link1['href'])\n",
    "req2 = requests.get(url2)\n",
    "soup2 = BeautifulSoup(req2.text, 'lxml')\n",
    "for link2 in soup2.findAll('a', href = True, text='Articole'):\n",
    "    if link2:\n",
    "        link2['href'] = 'http://mo.wikipedia.org' + link2['href'] \n",
    "        url3 = str(link2['href'])\n",
    "req3 = requests.get(url3)\n",
    "soup3 = BeautifulSoup(req3.text, 'lxml')\n",
    "for i, links in enumerate(soup3.findAll('a', href = True)):\n",
    "        if links:\n",
    "            links = '<i>{}.</i>  {}'.format(i, links)\n",
    "            display(HTML(str(links)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ДЗ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Написать краулер, который собирает тексты с новостного ресурса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = 'http://vechufa.ru/news/page/'\n",
    "j = 1\n",
    "for i in range(1,101):\n",
    "    req = requests.get(url+str(i)+'/')\n",
    "    soup = BeautifulSoup(req.text, 'lxml')\n",
    "    for h in soup.findAll('div', attrs = {'class':'full-right'}):\n",
    "        if h is not None:\n",
    "            link = h.find('a')['href']\n",
    "            req2 = requests.get(str(link))\n",
    "            soup2 = BeautifulSoup(req2.text, 'lxml')\n",
    "            f = open(str(j) + '.txt', 'w', encoding='utf-8')\n",
    "            for t in soup2.findAll('div', attrs = {'class':'text-content'}):\n",
    "                author = t.find('div', attrs={'style':'text-align:right;'})\n",
    "                if author:\n",
    "                    f.write('@au' + ' ' + author.text + '\\n')\n",
    "                else:\n",
    "                    f.write('@au' + ' ' + 'Noname' + '\\n')\n",
    "                hea = t.find('h1')\n",
    "                if hea:\n",
    "                    f.write('@ti' + ' ' + hea.text + '\\n')\n",
    "                date = t.find('div', attrs={'class':'full'})\n",
    "                if date:\n",
    "                    f.write('@da' + ' ' + date.p.contents[1] + '\\n')\n",
    "                f.write('@url'+ ' ' + req2.url + '\\n')\n",
    "                te = t.find('div', attrs={'style':'display:inline;'})\n",
    "                if te:\n",
    "                    f.write(te.text)\n",
    "            f.close()\n",
    "            j+=1\n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "\n",
    "                \n",
    "                \n",
    "                    \n",
    "                    \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
